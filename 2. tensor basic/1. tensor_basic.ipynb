{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 텐서와 Autograd\n",
    "\n",
    "## 3.1.1 텐서 다루기 기본:  차원(Rank)과 Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Size: torch.Size([3, 3])\n",
      "Shape: torch.Size([3, 3])\n",
      "랭크(차원): 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "x = torch.tensor([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(x)\n",
    "print(\"Size:\", x.size())\n",
    "print(\"Shape:\", x.shape)\n",
    "print(\"랭크(차원):\", x.ndimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n",
      "Size: torch.Size([1, 3])\n",
      "Shape: torch.Size([1, 3])\n",
      "랭크(차원): 2\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3]])\n",
    "print(x)\n",
    "print(\"Size:\", x.size())\n",
    "print(\"Shape:\", x.shape)\n",
    "print(\"랭크(차원):\", x.ndimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "Size: torch.Size([3, 1])\n",
      "Shape: torch.Size([3, 1])\n",
      "랭크(차원): 2\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1],[2],[3]])\n",
    "print(x)\n",
    "print(\"Size:\", x.size())\n",
    "print(\"Shape:\", x.shape)\n",
    "print(\"랭크(차원):\", x.ndimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.newaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3) torch.Size([3, 3]) (3, 3)\n",
      "(1, 3, 3) torch.Size([1, 3, 3]) (1, 3, 3)\n",
      "(1, 3, 3) torch.Size([1, 3, 3]) (1, 3, 3)\n",
      "(3, 1, 3) torch.Size([3, 1, 3]) (3, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "base_array = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "numpy_array = np.array(base_array)\n",
    "torch_tensor = torch.tensor(base_array)\n",
    "keras_tensor = backend.constant(base_array)\n",
    "\n",
    "print(numpy_array.shape, torch_tensor.shape, keras_tensor.shape)\n",
    "print(np.expand_dims(numpy_array, axis=0).shape, \n",
    "      torch_tensor.unsqueeze(dim=0).shape,\n",
    "     backend.expand_dims(keras_tensor, axis=0).shape)\n",
    "print(numpy_array[None].shape, torch_tensor[None].shape, keras_tensor[None].shape)\n",
    "print(numpy_array[:, None].shape, torch_tensor[:, None].shape, keras_tensor[:, None].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1) torch.Size([1, 3, 3, 1]) (1, 3, 3, 1)\n",
      "(3, 3) torch.Size([3, 3]) (3, 3, 1)\n",
      "(3, 3, 1) torch.Size([3, 3, 1]) (3, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "base_array = np.ones((1, 3, 3, 1))\n",
    "\n",
    "numpy_array = np.array(base_array)\n",
    "torch_tensor = torch.tensor(base_array)\n",
    "keras_tensor = backend.constant(base_array)\n",
    "print(numpy_array.shape, torch_tensor.shape, keras_tensor.shape)\n",
    "print(np.squeeze(numpy_array).shape, \n",
    "      torch_tensor.squeeze().shape,\n",
    "     backend.squeeze(keras_tensor, axis=0).shape)\n",
    "print(np.squeeze(numpy_array, axis=0).shape, \n",
    "      torch_tensor.squeeze(dim=0).shape,\n",
    "     backend.squeeze(keras_tensor, axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X 의 shape (512,512) => x.view(-1,256,256) => x.shape = (4,256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_array = np.ones((32, 3, 256, 256))\n",
    "keras_array = np.ones((32, 256, 256, 3))\n",
    "\n",
    "numpy_array = np.array(base_array)\n",
    "torch_tensor = torch.tensor(base_array)\n",
    "keras_tensor = backend.constant(keras_array)\n",
    "\n",
    "\n",
    "reshape_keras_tensor = backend.permute_dimensions(keras_tensor, (0, 3, 1, 2))\n",
    "reshape_keras_tensor = backend.reshape(keras_tensor, (96, 1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 1, 256, 256)\n",
      "torch.Size([96, 1, 256, 256])\n",
      "(96, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "print(numpy_array.reshape(-1, 1, 256, 256).shape)\n",
    "print(torch_tensor.reshape(-1, 1, 256, 256).shape)\n",
    "print(reshape_keras_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 9)\n",
      "torch.Size([5, 9])\n"
     ]
    }
   ],
   "source": [
    "base_array = [[1, 2, 3]]\n",
    "\n",
    "tile_coef = [2, 4]\n",
    "\n",
    "numpy_array = np.array(base_array)\n",
    "torch_tensor = torch.tensor(base_array)\n",
    "keras_tensor = backend.constant(keras_array)\n",
    "\n",
    "print(np.tile(numpy_array, [5, 3]).shape)\n",
    "print(torch.tile(torch_tensor, dims=[5, 3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 10])\n",
      "tensor([[0.0806, 0.1110, 0.0649, 0.1206, 0.0430, 0.0909, 0.1475, 0.1461, 0.1366,\n",
      "         0.0587],\n",
      "        [0.0733, 0.2067, 0.0088, 0.1746, 0.0784, 0.0467, 0.0785, 0.0747, 0.2232,\n",
      "         0.0351]])\n",
      "Shape: torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Softmax\n",
    "# 랭크의 형태 바꾸기\n",
    "x = torch.randn(2,10)\n",
    "print(\"Size:\", x.size())\n",
    "x = Softmax(dim=1)(x) # (?,1)\n",
    "print(x)\n",
    "print(\"Shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Layer 내부 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "test_layer = nn.Linear(32, 64, bias=True)\n",
    "\n",
    "print(test_layer.weight.shape)\n",
    "print(test_layer.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "test_layer = nn.Conv2d(32, 64, 3, bias=True)\n",
    "\n",
    "print(test_layer.weight.shape)\n",
    "print(test_layer.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 간단한 모델을 다양한 방법으로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(3, 32)\n",
    "        self.layer_2 = nn.Linear(32, 64)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_input = nn.Linear(3, 32)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Linear(64, 128)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, 3]\n",
    "        x = self.layer_input(x)\n",
    "        # x.shape: [B, 32]\n",
    "        x = self.layer(x)\n",
    "        # x.shape: [B, 32] => [B, 64] => [B, 128]\n",
    "        return x\n",
    "    \n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, depth=2):\n",
    "        super().__init__()\n",
    "        self.layer_input = nn.Linear(3, 32)\n",
    "        layer_list = []\n",
    "        for idx in range(1, depth + 1):\n",
    "            layer = nn.Linear(32 * idx, 32 * (idx + 1))\n",
    "            layer_list.append(layer)\n",
    "        self.layer = nn.Sequential(*layer_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, 3]\n",
    "        x = self.layer_input(x)\n",
    "        # x.shape: [B, 32]\n",
    "        x = self.layer(x)\n",
    "        # x.shape: [B, 32] => [B, 64] => [B, 128]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModuleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(isinstance(\"a\", str))\n",
    "print(isinstance(test_layer, nn.Module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, depth=2):\n",
    "        super().__init__()\n",
    "        self.layer_input = nn.Linear(3, 32)\n",
    "        layer_list = [nn.Linear(32 * idx, 32 * (idx + 1))\n",
    "                           for idx in range(1, depth + 1)]\n",
    "        self.layer_list = nn.ModuleList(layer_list)\n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, 3]\n",
    "        x = self.layer_input(x)\n",
    "        # x.shape: [B, 32]\n",
    "        for layer in self.layer_list:\n",
    "            x = layer(x)\n",
    "        # x.shape: [B, 32] => [B, 64] => [B, 128]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModuleDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 4,\n",
       " '3': 9,\n",
       " '4': 16,\n",
       " '5': 25,\n",
       " '6': 36,\n",
       " '7': 49,\n",
       " '8': 64,\n",
       " '9': 81}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{f\"{idx}\": idx ** 2 for idx in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, depth=2):\n",
    "        super().__init__()\n",
    "        self.layer_input = nn.Linear(3, 32)\n",
    "        layer_dict = {f\"layer_{idx}\":nn.Linear(32 * idx, 32 * (idx + 1))\n",
    "                       for idx in range(1, depth + 1)}\n",
    "        self.layer_dict = nn.ModuleDict(layer_dict)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, 3]\n",
    "        x = self.layer_input(x)\n",
    "        # x.shape: [B, 32]\n",
    "        for layer_name, layer in self.layer_dict.items():\n",
    "            x = layer(x)\n",
    "        # x.shape: [B, 32] => [B, 64] => [B, 128]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleDict(\n",
      "  (layer_1): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (layer_2): Linear(in_features=64, out_features=96, bias=True)\n",
      "  (layer_3): Linear(in_features=96, out_features=128, bias=True)\n",
      "  (layer_4): Linear(in_features=128, out_features=160, bias=True)\n",
      "  (layer_5): Linear(in_features=160, out_features=192, bias=True)\n",
      ")\n",
      "torch.Size([3, 192])\n"
     ]
    }
   ],
   "source": [
    "base_array = np.ones((3, 3))\n",
    "# torch_tensor = torch.tensor(base_array, dtype=torch.float32)\n",
    "torch_tensor = torch.tensor(base_array).float().cuda()\n",
    "\n",
    "model = SimpleModel(depth=5).cuda()\n",
    "print(model.layer_dict)\n",
    "print(model(torch_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uint8\n",
    "float32 => Float\n",
    "float64 => Double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
